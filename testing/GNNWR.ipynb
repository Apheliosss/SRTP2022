{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from Mydataset import MYDataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import clear_output as clear\n",
    "import statsmodels.api as sm\n",
    "from SWNN import SWNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "varName = ['fCO2', 'Chl', 'Temp', 'Salt']\n",
    "\n",
    "dataset = pd.read_csv(\"D://CO2_data5.csv\", encoding=\"utf-8\")\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset[dataset.index % 4 == 0]\n",
    "\n",
    "df0 = dataset['date'].str.split(\"/\",expand = True)\n",
    "df0.columns = ['year', 'month', 'date']\n",
    "\n",
    "dataset['month'] = df0['month']\n",
    "dataset = dataset[dataset.month == '7']\n",
    "\n",
    "train_li = random.sample([i for i in range(0, dataset.shape[0])], int(0.8 * dataset.shape[0]))\n",
    "train_li.sort()\n",
    "\n",
    "test_li = list(set([i for i in range(0, dataset.shape[0])]) - set(train_li))\n",
    "test_li.sort()\n",
    "\n",
    "train_set = dataset.iloc[train_li, :]\n",
    "test_set  = dataset.iloc[test_li,  :]\n",
    "\n",
    "mean_li = []\n",
    "std_li = []\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    mean_li.append(train_set[varName[i]].mean())\n",
    "    std_li.append(train_set[varName[i]].std())\n",
    "\n",
    "train_set = train_set.copy()\n",
    "test_set = test_set.copy()\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    train_set.loc[:, varName[i]] = (train_set[varName[i]] - mean_li[i] + 1.0) / std_li[i]\n",
    "    test_set.loc[:, varName[i]] = (test_set[varName[i]] - mean_li[i] + 1.0) / std_li[i]\n",
    "\n",
    "del mean_li, std_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(P, C):\n",
    "    A = (P**2).sum(axis=1, keepdims=True)\n",
    "    B = (C**2).sum(axis=1, keepdims=True).T\n",
    " \n",
    "    return np.sqrt(A + B - 2* np.dot(P, C.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1621"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(my_set, varName):\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    dataset = my_set.reset_index(drop=True)\n",
    "    ycor = dataset.lat\n",
    "\n",
    "    temp_df['label'] = dataset[varName[0]]\n",
    "    temp_df['beta'] = np.ones(dataset.shape[0])\n",
    "    temp_df[varName[1:4]] = dataset[varName[1:4]]\n",
    "\n",
    "    alist = dataset.lon\n",
    "    temp = []\n",
    "    for i in alist:\n",
    "        if i < 0:\n",
    "            i = i+360\n",
    "        temp.append(i)\n",
    "    xcor = temp\n",
    "\n",
    "    cor_df = pd.DataFrame()\n",
    "    cor_df['xcor'] = xcor\n",
    "    cor_df['ycor'] = ycor\n",
    "\n",
    "    sample_pt = np.array([[110.0, 0.0], [290.0,0.0], [110.0, 70.0], [290.0, 70.0]])\n",
    "\n",
    "    cor_li = cor_df.to_numpy()\n",
    "    dis_li = compute_distances(cor_li, sample_pt)\n",
    "    dis_df = pd.DataFrame(dis_li)\n",
    "    temp_df = temp_df.join(dis_df)\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "\n",
    "train_data = MYDataset(process_df(my_set=train_set, varName=varName), len(varName))\n",
    "test_data = MYDataset(process_df(my_set=test_set, varName=varName), len(varName))\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation = str()\n",
    "relation = varName[0]+\"~\" + \"+\".join(varName[1:len(varName)])\n",
    "fit=sm.formula.ols(relation,data=train_set).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SWNN(outsize=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fCO2+Chl~Temp~Salt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varName[0]+\"+\" + \"~\".join(varName[1:len(varName)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 0\n",
    "weightlist = [[]]\n",
    "temp = []\n",
    "for j in fit.params:\n",
    "    weightlist[0].append(j)\n",
    "#weightlist.append(temp)\n",
    "out = nn.Linear(4, 1, bias = False)\n",
    "out.weight = nn.Parameter(torch.tensor(weightlist), requires_grad=False)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    global r2\n",
    "    global out\n",
    "    for data, coef, label in train_loader:\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        label = label.view(data.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.mul(coef)\n",
    "        output = out(output)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        a = output.view(-1).detach().numpy()\n",
    "        b = label.view(-1).numpy()\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(a, b)\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('\\r Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    global out\n",
    "    global r2\n",
    "    val_loss = 0\n",
    "\n",
    "    label_li = np.array([])\n",
    "    out_li = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, coef, label in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            label = label.view(data.shape[0], -1)\n",
    "\n",
    "            output = model(data)\n",
    "            output = output.mul(coef)\n",
    "            output = out(output)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            a = output.view(-1).detach().numpy()\n",
    "            b = label.view(-1).numpy()\n",
    "            out_li = np.append(out_li, a)\n",
    "            label_li = np.append(label_li, b)\n",
    "\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "        val_loss = val_loss/len(test_loader.dataset)\n",
    "        label_li = np.array(label_li).reshape(-1)\n",
    "        out_li = np.array(out_li).reshape(-1)\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(out_li, label_li)\n",
    "        print('\\r Epoch: {} \\tTraining Loss: {:.6f} \\tR2: {:.6f}'.format(epoch, val_loss, r2))\n",
    "        if epoch % 2 == 0:\n",
    "            clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1000\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     val(epoch\u001b[39m=\u001b[39mepoch)\n",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 11\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mglobal\u001b[39;00m r2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mglobal\u001b[39;00m out\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m data, coef, label \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\SRTP2022\\testing\\Mydataset.py:21\u001b[0m, in \u001b[0;36mMYDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(image, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     20\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(label, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m---> 21\u001b[0m coef \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(coef, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat)\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m image, coef, label\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1000+1):\n",
    "    train(epoch=epoch)\n",
    "    val(epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, coef, label in train_loader:\n",
    "    print(label.view(50,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861f9c34f7302a1aedb62edfc1533c524ce2793735e6b405602ea89eb9cb2484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
