{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from Mydataset import MYDataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import clear_output as clear\n",
    "import statsmodels.api as sm\n",
    "from SWNN import SWNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "varName = ['fCO2', 'Chl', 'Temp', 'Salt']\n",
    "\n",
    "dataset = pd.read_csv(\"D://CO2_data5.csv\", encoding=\"utf-8\")\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset[dataset.index % 4 == 0]\n",
    "\n",
    "df0 = dataset['date'].str.split(\"/\",expand = True)\n",
    "df0.columns = ['year', 'month', 'date']\n",
    "\n",
    "dataset['month'] = df0['month']\n",
    "dataset = dataset[dataset.month == '7']\n",
    "\n",
    "train_li = random.sample([i for i in range(0, dataset.shape[0])], int(0.8 * dataset.shape[0]))\n",
    "train_li.sort()\n",
    "\n",
    "j = 0\n",
    "test_li = []\n",
    "\n",
    "for i in range(0, dataset.shape[0], 1):\n",
    "    if i != train_li[j] | j >= len(train_li):\n",
    "        test_li.append(i)\n",
    "    else:\n",
    "        j = j + 1\n",
    "\n",
    "train_set = dataset.iloc[train_li, :]\n",
    "test_set  = dataset.iloc[test_li,  :]\n",
    "\n",
    "mean_li = []\n",
    "std_li = []\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    mean_li.append(train_set[varName[i]].mean())\n",
    "    std_li.append(train_set[varName[i]].std())\n",
    "\n",
    "train_set = train_set.copy()\n",
    "test_set = test_set.copy()\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    train_set.loc[:, varName[i]] = (train_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
    "    test_set.loc[:, varName[i]] = (test_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(P, C):\n",
    "    A = (P**2).sum(axis=1, keepdims=True)\n",
    "    B = (C**2).sum(axis=1, keepdims=True).T\n",
    " \n",
    "    return np.sqrt(A + B - 2* np.dot(P, C.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fCO2</th>\n",
       "      <th>Chl</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Salt</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132516</th>\n",
       "      <td>2010/7/16</td>\n",
       "      <td>173.25</td>\n",
       "      <td>55.25</td>\n",
       "      <td>0.379430</td>\n",
       "      <td>1.281975</td>\n",
       "      <td>-1.738287</td>\n",
       "      <td>0.386586</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132520</th>\n",
       "      <td>2010/7/16</td>\n",
       "      <td>-168.75</td>\n",
       "      <td>66.75</td>\n",
       "      <td>-2.759659</td>\n",
       "      <td>2.232367</td>\n",
       "      <td>-1.903447</td>\n",
       "      <td>0.381619</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132524</th>\n",
       "      <td>2010/7/16</td>\n",
       "      <td>173.75</td>\n",
       "      <td>56.75</td>\n",
       "      <td>0.305969</td>\n",
       "      <td>1.245255</td>\n",
       "      <td>-1.702248</td>\n",
       "      <td>0.349873</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132528</th>\n",
       "      <td>2010/7/16</td>\n",
       "      <td>174.75</td>\n",
       "      <td>56.75</td>\n",
       "      <td>-0.467146</td>\n",
       "      <td>1.222401</td>\n",
       "      <td>-1.791050</td>\n",
       "      <td>0.301272</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132532</th>\n",
       "      <td>2010/7/16</td>\n",
       "      <td>174.75</td>\n",
       "      <td>57.25</td>\n",
       "      <td>-0.404352</td>\n",
       "      <td>1.380749</td>\n",
       "      <td>-1.741096</td>\n",
       "      <td>0.270506</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263880</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.75</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.921513</td>\n",
       "      <td>0.937207</td>\n",
       "      <td>1.387684</td>\n",
       "      <td>-0.164779</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263884</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.25</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.869110</td>\n",
       "      <td>0.934032</td>\n",
       "      <td>1.396153</td>\n",
       "      <td>-0.232795</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263888</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.640634</td>\n",
       "      <td>0.961555</td>\n",
       "      <td>1.416420</td>\n",
       "      <td>-0.236239</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263892</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.25</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.956775</td>\n",
       "      <td>0.937405</td>\n",
       "      <td>1.387597</td>\n",
       "      <td>-0.284868</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263896</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>136.75</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.896706</td>\n",
       "      <td>0.937386</td>\n",
       "      <td>1.386560</td>\n",
       "      <td>-0.375653</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3329 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     lon    lat      fCO2       Chl      Temp      Salt month\n",
       "132516  2010/7/16  173.25  55.25  0.379430  1.281975 -1.738287  0.386586     7\n",
       "132520  2010/7/16 -168.75  66.75 -2.759659  2.232367 -1.903447  0.381619     7\n",
       "132524  2010/7/16  173.75  56.75  0.305969  1.245255 -1.702248  0.349873     7\n",
       "132528  2010/7/16  174.75  56.75 -0.467146  1.222401 -1.791050  0.301272     7\n",
       "132532  2010/7/16  174.75  57.25 -0.404352  1.380749 -1.741096  0.270506     7\n",
       "...           ...     ...    ...       ...       ...       ...       ...   ...\n",
       "263880  2020/7/16  137.75  13.25  0.921513  0.937207  1.387684 -0.164779     7\n",
       "263884  2020/7/16  137.25  12.75  0.869110  0.934032  1.396153 -0.232795     7\n",
       "263888  2020/7/16  137.75   8.75  0.640634  0.961555  1.416420 -0.236239     7\n",
       "263892  2020/7/16  137.25  14.25  0.956775  0.937405  1.387597 -0.284868     7\n",
       "263896  2020/7/16  136.75  14.25  0.896706  0.937386  1.386560 -0.375653     7\n",
       "\n",
       "[3329 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(my_set, varName):\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    dataset = my_set.reset_index(drop=True)\n",
    "    ycor = dataset.lat\n",
    "\n",
    "    temp_df['label'] = dataset[varName[0]]\n",
    "    temp_df['beta'] = np.ones(dataset.shape[0])\n",
    "    temp_df[varName[1:4]] = dataset[varName[1:4]]\n",
    "\n",
    "    alist = dataset.lon\n",
    "    temp = []\n",
    "    for i in alist:\n",
    "        if i < 0:\n",
    "            i = i+360\n",
    "        temp.append(i)\n",
    "    xcor = temp\n",
    "\n",
    "    cor_df = pd.DataFrame()\n",
    "    cor_df['xcor'] = xcor\n",
    "    cor_df['ycor'] = ycor\n",
    "\n",
    "    a = [[110.0, 0.0], [290.0,0.0], [110.0, 70.0], [290.0, 70.0]]\n",
    "    b = np.array(a)\n",
    "\n",
    "    cor_li = cor_df.to_numpy()\n",
    "    dis_li = compute_distances(cor_li, b)\n",
    "    dis_df = pd.DataFrame(dis_li)\n",
    "    temp_df = temp_df.join(dis_df)\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "\n",
    "train_data = MYDataset(process_df(my_set=train_set, varName=varName), len(varName))\n",
    "test_data = MYDataset(process_df(my_set=test_set, varName=varName), len(varName))\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12559232957822922\n"
     ]
    }
   ],
   "source": [
    "relation = str()\n",
    "relation = varName[0]+'~'+varName[1]\n",
    "for i in range(2, len(varName), 1):\n",
    "    relation = relation + '+' + varName[i]\n",
    "fit=sm.formula.ols(relation,data=train_set).fit()\n",
    "print(fit.params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = SWNN(outsize=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r2 = 0\n",
    "weightlist = []\n",
    "temp = []\n",
    "for j in fit.params:\n",
    "    temp.append(j)\n",
    "weightlist.append(temp)\n",
    "out = nn.Linear(4, 1, bias = False)\n",
    "out.weight = nn.Parameter(torch.tensor(weightlist), requires_grad=False)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    global r2\n",
    "    global out\n",
    "    for data, coef, label in train_loader:\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        label = label.view(data.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.mul(coef)\n",
    "        output = out(output)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        a = output.view(-1).detach().numpy()\n",
    "        b = label.view(-1).numpy()\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(a, b)\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('\\r Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    global out\n",
    "    global r2\n",
    "    val_loss = 0\n",
    "\n",
    "    label_li = np.array([])\n",
    "    out_li = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, coef, label in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            label = label.view(data.shape[0], -1)\n",
    "\n",
    "            output = model(data)\n",
    "            output = output.mul(coef)\n",
    "            output = out(output)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            a = output.view(-1).detach().numpy()\n",
    "            b = label.view(-1).numpy()\n",
    "            out_li = np.append(out_li, a)\n",
    "            label_li = np.append(label_li, b)\n",
    "            \n",
    "\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "        val_loss = val_loss/len(test_loader.dataset)\n",
    "        label_li = np.array(label_li).reshape(-1)\n",
    "        out_li = np.array(out_li).reshape(-1)\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(out_li, label_li)\n",
    "        #print(out_li)\n",
    "        print('\\r Epoch: {} \\tTraining Loss: {:.6f} \\tR2: {:.6f}'.format(epoch, val_loss, r2))\n",
    "        if epoch % 2 == 0:\n",
    "            clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 49 \tTraining Loss: 0.509350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1000\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(epoch\u001b[39m=\u001b[39mepoch)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     val(epoch\u001b[39m=\u001b[39;49mepoch)\n",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 10\u001b[0m in \u001b[0;36mval\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m out_li \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data, coef, label \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\SRTP2022\\testing\\Mydataset.py:21\u001b[0m, in \u001b[0;36mMYDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(image, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     20\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(label, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m---> 21\u001b[0m coef \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(coef, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat)\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m image, coef, label\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1000+1):\n",
    "    train(epoch=epoch)\n",
    "    val(epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, coef, label in train_loader:\n",
    "    print(label.view(50,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861f9c34f7302a1aedb62edfc1533c524ce2793735e6b405602ea89eb9cb2484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
