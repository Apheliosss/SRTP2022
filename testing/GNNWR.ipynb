{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import clear_output as clear\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.images = df.iloc[:,5:].values\n",
    "        self.coef = df.iloc[:,1:5].values\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        coef = self.coef[idx]\n",
    "        \n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "        coef = torch.tensor(coef, dtype=torch.float)\n",
    "\n",
    "        return image, coef, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Temp\\ipykernel_29984\\999894338.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, varName[i]] = (train_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
      "D:\\Temp\\ipykernel_29984\\999894338.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, varName[i]] = (test_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n"
     ]
    }
   ],
   "source": [
    "varName = ['fCO2', 'Chl', 'Temp', 'Salt']\n",
    "\n",
    "dataset = pd.read_csv(\"D://CO2_data4.csv\", encoding=\"utf-8\")\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset[dataset.index % 4 == 0]\n",
    "\n",
    "df0 = dataset['date'].str.split(\"/\",expand = True)\n",
    "df0.columns = ['year', 'month', 'date']\n",
    "\n",
    "dataset['month'] = df0['month']\n",
    "dataset = dataset[dataset.month == '7']\n",
    "\n",
    "train_li = random.sample([i for i in range(0, dataset.shape[0])], int(0.8 * dataset.shape[0]))\n",
    "train_li.sort()\n",
    "\n",
    "j = 0\n",
    "test_li = []\n",
    "\n",
    "for i in range(0, dataset.shape[0], 1):\n",
    "    if i != train_li[j] | j >= len(train_li):\n",
    "        test_li.append(i)\n",
    "    else:\n",
    "        j = j + 1\n",
    "\n",
    "train_set = dataset.iloc[train_li, :]\n",
    "test_set  = dataset.iloc[test_li,  :]\n",
    "\n",
    "mean_li = []\n",
    "std_li = []\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    mean_li.append(train_set[varName[i]].mean())\n",
    "    std_li.append(train_set[varName[i]].std())\n",
    "\n",
    "for i in range(0, len(varName), 1):\n",
    "    train_set.loc[:, varName[i]] = (train_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
    "    test_set.loc[:, varName[i]] = (test_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(P, C):\n",
    "    A = (P**2).sum(axis=1, keepdims=True)\n",
    " \n",
    "    B = (C**2).sum(axis=1, keepdims=True).T\n",
    " \n",
    "    return np.sqrt(A + B - 2* np.dot(P, C.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fCO2</th>\n",
       "      <th>Chl</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Salt</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-116.75</td>\n",
       "      <td>28.25</td>\n",
       "      <td>1.241139</td>\n",
       "      <td>0.745263</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>2.553028</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>131.75</td>\n",
       "      <td>36.25</td>\n",
       "      <td>0.141260</td>\n",
       "      <td>0.905653</td>\n",
       "      <td>1.407171</td>\n",
       "      <td>1.894994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>145.25</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-0.590107</td>\n",
       "      <td>0.939269</td>\n",
       "      <td>0.535674</td>\n",
       "      <td>1.684783</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>170.75</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.578059</td>\n",
       "      <td>0.832415</td>\n",
       "      <td>0.870099</td>\n",
       "      <td>1.648535</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>136.25</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.980314</td>\n",
       "      <td>0.667182</td>\n",
       "      <td>2.250066</td>\n",
       "      <td>1.510432</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>-178.25</td>\n",
       "      <td>43.25</td>\n",
       "      <td>0.770155</td>\n",
       "      <td>1.613718</td>\n",
       "      <td>0.046663</td>\n",
       "      <td>1.140538</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>-129.75</td>\n",
       "      <td>35.25</td>\n",
       "      <td>2.345260</td>\n",
       "      <td>0.713546</td>\n",
       "      <td>0.650646</td>\n",
       "      <td>0.983335</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>151.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.293473</td>\n",
       "      <td>0.670695</td>\n",
       "      <td>2.345796</td>\n",
       "      <td>0.513952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>-171.75</td>\n",
       "      <td>50.75</td>\n",
       "      <td>1.726052</td>\n",
       "      <td>0.842360</td>\n",
       "      <td>-0.444046</td>\n",
       "      <td>0.418292</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>147.25</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.276233</td>\n",
       "      <td>0.668982</td>\n",
       "      <td>2.329123</td>\n",
       "      <td>0.112629</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     lon    lat      fCO2       Chl      Temp      Salt month\n",
       "12    1998/7/16 -116.75  28.25  1.241139  0.745263  0.936183  2.553028     7\n",
       "28    1998/7/16  131.75  36.25  0.141260  0.905653  1.407171  1.894994     7\n",
       "52    1998/7/16  145.25  41.75 -0.590107  0.939269  0.535674  1.684783     7\n",
       "56    1998/7/16  170.75  37.75  0.578059  0.832415  0.870099  1.648535     7\n",
       "72    1998/7/16  136.25  15.75  0.980314  0.667182  2.250066  1.510432     7\n",
       "...         ...     ...    ...       ...       ...       ...       ...   ...\n",
       "6368  2020/7/16 -178.25  43.25  0.770155  1.613718  0.046663  1.140538     7\n",
       "6388  2020/7/16 -129.75  35.25  2.345260  0.713546  0.650646  0.983335     7\n",
       "6432  2020/7/16  151.25   3.25  1.293473  0.670695  2.345796  0.513952     7\n",
       "6440  2020/7/16 -171.75  50.75  1.726052  0.842360 -0.444046  0.418292     7\n",
       "6488  2020/7/16  147.25   6.75  1.276233  0.668982  2.329123  0.112629     7\n",
       "\n",
       "[331 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(my_set):\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    dataset = my_set.reset_index(drop=True)\n",
    "    ycor = dataset.lat\n",
    "    #ycor = dataset.lon\n",
    "    label = dataset.fCO2\n",
    "\n",
    "    temp_df['label'] = label\n",
    "\n",
    "    temp_df['beta'] = np.ones(dataset.shape[0])\n",
    "    temp_df['Chl'] = dataset.Chl\n",
    "    temp_df['Temp'] = dataset.Temp\n",
    "    temp_df['Salt'] = dataset.Salt\n",
    "\n",
    "    alist = dataset.lon\n",
    "    temp = []\n",
    "    for i in alist:\n",
    "        if i < 0:\n",
    "            i = i+360\n",
    "        temp.append(i)\n",
    "    xcor = temp\n",
    "\n",
    "    cor_df = pd.DataFrame()\n",
    "    cor_df['xcor'] = xcor\n",
    "    cor_df['ycor'] = ycor\n",
    "\n",
    "    a = [[110.0, 0.0], [290.0,0.0], [110.0, 70.0], [290.0, 70.0]]\n",
    "    b = np.array(a)\n",
    "\n",
    "    cor_li = cor_df.to_numpy()\n",
    "    dis_li = compute_distances(cor_li, b)\n",
    "    dis_df = pd.DataFrame(dis_li)\n",
    "    temp_df = temp_df.join(dis_df)\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "\n",
    "train_data = MYDataset(process_df(my_set=train_set))\n",
    "test_data = MYDataset(process_df(my_set=test_set))\n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=50, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fCO2</th>\n",
       "      <th>Chl</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Salt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-110.25</td>\n",
       "      <td>22.25</td>\n",
       "      <td>1.429020</td>\n",
       "      <td>0.932204</td>\n",
       "      <td>1.035501</td>\n",
       "      <td>3.714037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-111.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>0.653314</td>\n",
       "      <td>0.865872</td>\n",
       "      <td>0.980157</td>\n",
       "      <td>3.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-111.25</td>\n",
       "      <td>23.25</td>\n",
       "      <td>1.835711</td>\n",
       "      <td>0.874641</td>\n",
       "      <td>0.896934</td>\n",
       "      <td>3.617013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-112.25</td>\n",
       "      <td>23.25</td>\n",
       "      <td>1.925815</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.827733</td>\n",
       "      <td>3.544569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998/7/16</td>\n",
       "      <td>-112.25</td>\n",
       "      <td>24.25</td>\n",
       "      <td>1.836483</td>\n",
       "      <td>1.093919</td>\n",
       "      <td>0.710469</td>\n",
       "      <td>3.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.75</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1.178217</td>\n",
       "      <td>0.770692</td>\n",
       "      <td>1.481354</td>\n",
       "      <td>-0.398306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.25</td>\n",
       "      <td>12.75</td>\n",
       "      <td>1.116893</td>\n",
       "      <td>0.768039</td>\n",
       "      <td>1.489461</td>\n",
       "      <td>-0.467678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.849520</td>\n",
       "      <td>0.791038</td>\n",
       "      <td>1.508860</td>\n",
       "      <td>-0.471190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>137.25</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.219482</td>\n",
       "      <td>0.770857</td>\n",
       "      <td>1.481271</td>\n",
       "      <td>-0.520788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>2020/7/16</td>\n",
       "      <td>136.75</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.149187</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>1.480279</td>\n",
       "      <td>-0.613381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6604 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     lon    lat      fCO2       Chl      Temp      Salt\n",
       "0     1998/7/16 -110.25  22.25  1.429020  0.932204  1.035501  3.714037\n",
       "1     1998/7/16 -111.75  22.25  0.653314  0.865872  0.980157  3.665900\n",
       "2     1998/7/16 -111.25  23.25  1.835711  0.874641  0.896934  3.617013\n",
       "3     1998/7/16 -112.25  23.25  1.925815  0.861615  0.827733  3.544569\n",
       "4     1998/7/16 -112.25  24.25  1.836483  1.093919  0.710469  3.415906\n",
       "...         ...     ...    ...       ...       ...       ...       ...\n",
       "6599  2020/7/16  137.75  13.25  1.178217  0.770692  1.481354 -0.398306\n",
       "6600  2020/7/16  137.25  12.75  1.116893  0.768039  1.489461 -0.467678\n",
       "6601  2020/7/16  137.75   8.75  0.849520  0.791038  1.508860 -0.471190\n",
       "6602  2020/7/16  137.25  14.25  1.219482  0.770857  1.481271 -0.520788\n",
       "6603  2020/7/16  136.75  14.25  1.149187  0.770841  1.480279 -0.613381\n",
       "\n",
       "[6604 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNWR(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(GNNWR, self).__init__()\n",
    "        self.insize = insize\n",
    "        self.outsize = outsize\n",
    "\n",
    "        lastsize = self.insize\n",
    "        thissize = 0\n",
    "        self.fc = nn.Sequential()\n",
    "        i = 2\n",
    "\n",
    "        self.fc.add_module(\"full\"+str(1), nn.Linear(4, 600))\n",
    "        # self.fc.add_module(\"batc\"+str(1), nn.BatchNorm1d(600))\n",
    "        # self.fc.add_module(\"acti\"+str(1), nn.PReLU(init=0.4))\n",
    "        # self.fc.add_module(\"drop\"+str(1), nn.Dropout(0.2))\n",
    "\n",
    "        lastsize = 600\n",
    "        while math.pow(2, int(math.log2(lastsize))) >= max(128, outsize + 1):\n",
    "            if i == 1:\n",
    "                thissize = int(math.pow(2, int(math.log2(lastsize))))\n",
    "            else:\n",
    "                thissize = int(math.pow(2, int(math.log2(lastsize)) - 1))\n",
    "            \n",
    "            self.fc.add_module(\"full\"+str(i), nn.Linear(lastsize, thissize))\n",
    "            self.fc.add_module(\"batc\"+str(i), nn.BatchNorm1d(thissize))\n",
    "            self.fc.add_module(\"acti\"+str(i), nn.PReLU(init=0.4))\n",
    "            \n",
    "            self.fc.add_module(\"drop\"+str(i), nn.Dropout(0.2))\n",
    "\n",
    "            lastsize = thissize\n",
    "            i = i + 1\n",
    "\n",
    "        self.fc.add_module(\"full\"+str(i), nn.Linear(lastsize, outsize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = GNNWR(623, 4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r2 = 0\n",
    "weightlist = []\n",
    "for i in range(1,2):\n",
    "    temp = []\n",
    "    temp.append(-0.172075)\n",
    "    temp.append(-0.175203)\n",
    "    temp.append(0.294790)\n",
    "    temp.append(0.385374)\n",
    "    weightlist.append(temp)\n",
    "out = nn.Linear(4, 1, bias = False)\n",
    "out.weight = nn.Parameter(torch.tensor(weightlist), requires_grad=False)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    global r2\n",
    "    global out\n",
    "    for data, coef, label in train_loader:\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        label = label.view(data.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.mul(coef)\n",
    "        output = out(output)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        a = output.view(-1).detach().numpy()\n",
    "        b = label.view(-1).numpy()\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(a, b)\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    global out\n",
    "    global r2\n",
    "    val_loss = 0\n",
    "\n",
    "    label_li = np.array([])\n",
    "    out_li = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, coef, label in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            label = label.view(data.shape[0], -1)\n",
    "\n",
    "            output = model(data)\n",
    "            output = output.mul(coef)\n",
    "            output = out(output)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            a = output.view(-1).detach().numpy()\n",
    "            b = label.view(-1).numpy()\n",
    "            out_li = np.append(out_li, a)\n",
    "            label_li = np.append(label_li, b)\n",
    "            \n",
    "\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "        val_loss = val_loss/len(test_loader.dataset)\n",
    "        label_li = np.array(label_li).reshape(-1)\n",
    "        out_li = np.array(out_li).reshape(-1)\n",
    "        if epoch % 100 == 0:\n",
    "            r2 = r2_score(out_li, label_li)\n",
    "        #print(out_li)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tR2: {:.6f}'.format(epoch, val_loss, r2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 237/1000 [03:06<11:43,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 237 \tTraining Loss: 0.586746\n",
      "Epoch: 237 \tTraining Loss: 0.502367 \tR2: 0.334928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 237/1000 [03:07<10:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 238 \tTraining Loss: 0.598425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1000\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(epoch)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     val(epoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m          clear()\n",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 11\u001b[0m in \u001b[0;36mval\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mview(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmul(coef)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m output \u001b[39m=\u001b[39m out(output)\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\SRTP2022\\testing\\GNNWR.ipynb Cell 11\u001b[0m in \u001b[0;36mGNNWR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SRTP2022/testing/GNNWR.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, 1000+1)):\n",
    "    train(epoch)\n",
    "    val(epoch)\n",
    "    if epoch % 2 ==0:\n",
    "         clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1321"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861f9c34f7302a1aedb62edfc1533c524ce2793735e6b405602ea89eb9cb2484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
