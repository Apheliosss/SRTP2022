{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MMnlQkeZD6eZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import  DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "class MYDataset(Dataset):\n",
        "    def __init__(self, df, varNum, gpu):\n",
        "        self.df = df\n",
        "        self.gpu = gpu\n",
        "        self.images = df.iloc[:,varNum+1:].values\n",
        "        self.coef = df.iloc[:,1:varNum+1].values\n",
        "        self.labels = df.iloc[:, 0].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        coef = self.coef[idx]\n",
        "        \n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        label = torch.tensor(label, dtype=torch.float)\n",
        "        coef = torch.tensor(coef, dtype=torch.float)\n",
        "\n",
        "        return image, coef, label\n",
        "\n",
        "class SWNN(nn.Module):\n",
        "    def __init__(self, insize, outsize):\n",
        "        super(SWNN, self).__init__()\n",
        "        self.insize = insize\n",
        "        self.outsize = outsize\n",
        "        self.thissize = 0\n",
        "        self.lastsize = 512\n",
        "        i = 2\n",
        "\n",
        "        self.fc = nn.Sequential()\n",
        "        self.fc.add_module(\"full\"+str(1), nn.Linear(self.insize, 512))\n",
        "\n",
        "\n",
        "        while math.pow(2, int(math.log2(self.lastsize))) >= max(128, outsize + 1):\n",
        "            if i == 1:\n",
        "                self.thissize = int(math.pow(2, int(math.log2(self.lastsize))))\n",
        "            else:\n",
        "                self.thissize = int(math.pow(2, int(math.log2(self.lastsize)) - 1))\n",
        "            \n",
        "            self.fc.add_module(\"full\"+str(i), nn.Linear(self.lastsize, self.thissize))\n",
        "            self.fc.add_module(\"batc\"+str(i), nn.BatchNorm1d(self.thissize))\n",
        "            self.fc.add_module(\"acti\"+str(i), nn.PReLU(init=0.4))\n",
        "            self.fc.add_module(\"drop\"+str(i), nn.Dropout(0.2))\n",
        "\n",
        "            self.lastsize = self.thissize\n",
        "            i = i + 1\n",
        "\n",
        "        self.fc.add_module(\"full\"+str(i), nn.Linear(self.lastsize, self.outsize))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def compute_distances(P, C):\n",
        "    A = (P**2).sum(axis=1, keepdims=True)\n",
        "    B = (C**2).sum(axis=1, keepdims=True).T\n",
        " \n",
        "    return np.sqrt(A + B - 2* np.dot(P, C.T))\n",
        "\n",
        "def process_df(my_set, varName):\n",
        "    temp_df = pd.DataFrame()\n",
        "\n",
        "    dataset = my_set.reset_index(drop=True)\n",
        "\n",
        "    temp_df['label'] = dataset[varName[0]]\n",
        "    temp_df['beta'] = np.ones(dataset.shape[0])\n",
        "    temp_df[varName[1:4]] = dataset[varName[1:4]]\n",
        "\n",
        "    cor_df = pd.DataFrame()\n",
        "\n",
        "    dataset['lon'][dataset['lon'] < 0] = dataset['lon'][dataset['lon'] < 0].copy() + 360.0\n",
        "    cor_df['xcor'] = dataset['lon']\n",
        "    cor_df['ycor'] = dataset['lat']\n",
        "\n",
        "    sample_pt = np.array([[110.0, 0.0], [290.0,0.0], [110.0, 70.0], [290.0, 70.0]])\n",
        "\n",
        "    cor_li = cor_df.to_numpy()\n",
        "    dis_li = compute_distances(cor_li, sample_pt)\n",
        "    dis_df = pd.DataFrame(dis_li)\n",
        "    temp_df = temp_df.join(dis_df)\n",
        "    temp_df['year'] = dataset['year'].astype('float') - 2008\n",
        "    temp_df['month'] = dataset['month'].astype('float') - 6\n",
        "\n",
        "    return temp_df\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    global r2\n",
        "    global out\n",
        "    for data, coef, label in train_loader:\n",
        "        data, coef, label = data.cuda(), coef.cuda(), label.cuda()\n",
        "        data, label = data.view(data.shape[0], -1), label.view(data.shape[0], -1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        output = output.mul(coef)\n",
        "        output = out(output)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    print('\\r Epoch: {} \\tTraining Loss:   {:.6f}'.format(epoch, train_loss))\n",
        "\n",
        "def val(epoch):\n",
        "    model.eval()\n",
        "    global out\n",
        "    global r2\n",
        "    global best_loss\n",
        "    global last_min\n",
        "    val_loss = 0\n",
        "\n",
        "    label_li = np.array([])\n",
        "    out_li = np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, coef, label in test_loader:\n",
        "            data, coef, label = data.cuda(), coef.cuda(), label.cuda()\n",
        "            data,label = data.view(data.shape[0], -1), label.view(data.shape[0], -1)\n",
        "\n",
        "            output = model(data).mul(coef)\n",
        "            output = out(output)\n",
        "\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            a = output.view(-1).cpu().detach().numpy()\n",
        "            b = label.view(-1).cpu().numpy()\n",
        "            out_li = np.append(out_li, a)\n",
        "            label_li = np.append(label_li, b)\n",
        "            \n",
        "\n",
        "            val_loss += loss.item()*data.size(0)\n",
        "        val_loss = val_loss/len(test_loader.dataset)\n",
        "        r2 = r2_score(label_li, out_li)\n",
        "        if r2 > best_loss:\n",
        "            best_loss = r2\n",
        "            last_min = 0\n",
        "            torch.save(model, \"model.pkl\")\n",
        "        else:\n",
        "            last_min = last_min + 1\n",
        "\n",
        "        label_li = np.array(label_li).reshape(-1)\n",
        "        out_li = np.array(out_li).reshape(-1)\n",
        "        \n",
        "        print('\\r Epoch: {} \\tValidation Loss: {:.6f} \\tR2: {:.6f}'.format(epoch, val_loss, best_loss))\n",
        "\n",
        "def select(data, ratio):\n",
        "    year = 0\n",
        "    month = 0\n",
        "    tdf = pd.DataFrame(columns=data.columns)\n",
        "    positive = pd.DataFrame(columns=data.columns)\n",
        "    nagative = pd.DataFrame(columns=data.columns)\n",
        "    index = -1\n",
        "    data.sort_values(by=['year', 'month'])\n",
        "    for i in tqdm(range(0,data.shape[0])):\n",
        "        if not year == data.loc[i]['year'] or not month == data.loc[i]['month']:\n",
        "            if not index == -1:\n",
        "                tp = tdf.sample(frac=ratio)\n",
        "                tn = tdf.append(tp)\n",
        "                tn.drop_duplicates(keep=False, inplace=True)\n",
        "\n",
        "                positive = positive.append(tp)\n",
        "                nagative = nagative.append(tn)\n",
        "            tdf = pd.DataFrame(columns=data.columns)\n",
        "            year = data.loc[i]['year']\n",
        "            month = data.loc[i]['month']\n",
        "            index = i\n",
        "        tdf.loc[i-index] = data.loc[i]\n",
        "    return positive, nagative\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    criterion1 = nn.MSELoss()\n",
        "    criterion2 = nn.L1Loss()\n",
        "    label_li = np.array([])\n",
        "    out_li = np.array([])\n",
        "    val_loss1 = 0\n",
        "    val_loss2 = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, coef, label in test_loader:\n",
        "            data, coef, label = data.cuda(), coef.cuda(), label.cuda()\n",
        "            data,label = data.view(data.shape[0], -1), label.view(data.shape[0], -1)\n",
        "\n",
        "            output = model(data).mul(coef)\n",
        "            output = out(output)\n",
        "\n",
        "            loss1 = criterion1(output, label)\n",
        "            loss2 = criterion2(output, label)\n",
        "\n",
        "            a = output.view(-1).cpu().detach().numpy()\n",
        "            b = label.view(-1).cpu().numpy()\n",
        "            out_li = np.append(out_li, a)\n",
        "            label_li = np.append(label_li, b)\n",
        "            \n",
        "\n",
        "            val_loss1 += loss1.item()*data.size(0)\n",
        "            val_loss2 += loss2.item()*data.size(0)\n",
        "\n",
        "        val_loss1 = val_loss1/len(test_loader.dataset)\n",
        "        val_loss2 = val_loss2/len(test_loader.dataset)\n",
        "        r2 = r2_score(label_li, out_li)\n",
        "\n",
        "        label_li = label_li * std_li[0] + mean_li[0]\n",
        "        out_li = out_li * std_li[0] + mean_li[0]\n",
        "\n",
        "\n",
        "\n",
        "        diff = np.abs(label_li - out_li)\n",
        "        diff = diff / np.abs(label_li) * 100\n",
        "\n",
        "        rmse = math.sqrt(val_loss1) * std_li[0]\n",
        "        mae  = val_loss2 * std_li[0]\n",
        "        mape = diff.mean()\n",
        "\n",
        "    print(r2, rmse, mae, mape)\n",
        "\n",
        "\n",
        "def full_img(path:str):\n",
        "    dataset = pd.read_csv(path, encoding=\"utf-8\")\n",
        "    dataset['fCO2'] = np.ones(dataset.shape[0])\n",
        "\n",
        "    for i in range(1, varNum, 1):\n",
        "      dataset.loc[:, varName[i]] = (dataset[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
        "\n",
        "    img_data = MYDataset(process_df(dataset, varName=varName), varNum=varNum, gpu=is_gpu)\n",
        "    img_loader = DataLoader(img_data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
        "    \n",
        "    model.eval()\n",
        "    out_li = np.array([])\n",
        "    with torch.no_grad():\n",
        "        for data, coef, label in img_loader:\n",
        "            data, coef, label = data.cuda(), coef.cuda(), label.cuda()\n",
        "            data,label = data.view(data.shape[0], -1), label.view(data.shape[0], -1)\n",
        "\n",
        "            output = model(data).mul(coef)\n",
        "            output = out(output)\n",
        "            a = output.view(-1).cpu().detach().numpy()\n",
        "\n",
        "            out_li = np.append(out_li, a)\n",
        "    return out_li * std_li[0] + mean_li[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BhUTWXfPGpdu"
      },
      "outputs": [],
      "source": [
        "\n",
        "is_gpu = None\n",
        "if torch.cuda.is_available() == True:\n",
        "    is_gpu = True\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "else:\n",
        "    is_gpu = False\n",
        "\n",
        "\n",
        "varName = ['fCO2', 'Chl', 'Temp', 'Salt']\n",
        "varNum = len(varName)\n",
        "batch_size = 256\n",
        "\n",
        "dataset = pd.read_csv(\"D://CO2_data5.csv\", encoding=\"utf-8\")\n",
        "dataset = dataset.dropna()\n",
        "dataset = dataset[dataset.index % 4 == 0]\n",
        "\n",
        "df0 = dataset['date'].str.split(\"/\",expand = True)\n",
        "df0.columns = ['year', 'month', 'date']\n",
        "\n",
        "dataset['month'] = df0['month']\n",
        "dataset['year'] = df0['year']\n",
        "\n",
        "dataset = dataset.reset_index()\n",
        "\n",
        "test_set, train_set = select(dataset, 0.2)\n",
        "del dataset\n",
        "#dataset = dataset[dataset.month == '7']\n",
        "\n",
        "# train_li = random.sample([i for i in range(0, dataset.shape[0])], int(0.8 * dataset.shape[0]))\n",
        "# train_li.sort()\n",
        "\n",
        "# test_li = list(set([i for i in range(0, dataset.shape[0])]) - set(train_li))\n",
        "# test_li.sort()\n",
        "\n",
        "# train_set = dataset.iloc[train_li, :]\n",
        "# test_set  = dataset.iloc[test_li,  :]\n",
        "\n",
        "mean_li = []\n",
        "std_li = []\n",
        "\n",
        "for i in range(0, varNum, 1):\n",
        "    mean_li.append(train_set[varName[i]].mean())\n",
        "    std_li.append(train_set[varName[i]].std())\n",
        "\n",
        "train_set = train_set.copy()\n",
        "test_set = test_set.copy()\n",
        "\n",
        "for i in range(0, varNum, 1):\n",
        "    train_set.loc[:, varName[i]] = (train_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
        "    test_set.loc[:, varName[i]] = (test_set[varName[i]].copy() - mean_li[i] + 1.0) / std_li[i]\n",
        "\n",
        "\n",
        "train_data = MYDataset(process_df(my_set=train_set, varName=varName), varNum, gpu=is_gpu)\n",
        "test_data = MYDataset(process_df(my_set=test_set, varName=varName), varNum, gpu=is_gpu)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uUc-h12nGzYs",
        "outputId": "8132b819-adac-4123-f321-8c334a51e0fd"
      },
      "outputs": [],
      "source": [
        "model = SWNN(insize=6, outsize=4)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "relation = str()\n",
        "relation = varName[0]+\"~\" + \"+\".join(varName[1:varNum])\n",
        "fit=sm.formula.ols(relation,data=train_set).fit()\n",
        "\n",
        "r2 = 0\n",
        "last_min = 0\n",
        "best_loss = -1\n",
        "weightlist = []\n",
        "temp = []\n",
        "for j in fit.params:\n",
        "    temp.append(j)\n",
        "weightlist.append(temp)\n",
        "out = nn.Linear(4, 1, bias = False)\n",
        "out.weight = nn.Parameter(torch.tensor(weightlist), requires_grad=False)\n",
        "\n",
        "if is_gpu:\n",
        "    model = model.cuda()\n",
        "    out = out.cuda()\n",
        "\n",
        "for epoch in range(1, 200000+1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    if last_min >= 2000:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV-v3AVagu9h",
        "outputId": "8e0f37f7-6848-4338-87f3-68da2defa3a0"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"model (1).pkl\")\n",
        "model = model.cuda()\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g02G5KT0JFCg"
      },
      "outputs": [],
      "source": [
        "li = full_img('201507.csv')\n",
        "dat = pd.read_csv(\"201507.csv\", encoding='utf-8')\n",
        "ab = pd.DataFrame()\n",
        "ab['fCO2'] = li\n",
        "ab['lon'] = dat['lon']\n",
        "ab['lat'] = dat['lat']\n",
        "ab.to_csv(\"fullimg4.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "861f9c34f7302a1aedb62edfc1533c524ce2793735e6b405602ea89eb9cb2484"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
